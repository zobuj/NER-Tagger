{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn_crfsuite import CRF\n",
    "\n",
    "class CustomCRF(CRF):\n",
    "    def feature_dict(self, x, y=None, state_features=None):\n",
    "        features = super().feature_dict(x, y, state_features)\n",
    "        return features\n",
    "crf = joblib.load('crf_model_with_induction.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i,pos_tags_,entity_patterns,token_list,chunks):\n",
    "    word = sent[i]\n",
    "    \n",
    "    if pos_tags_ != None:\n",
    "        postag = pos_tags_[i]\n",
    "    if pos_tags_ != None:\n",
    "        features = {\n",
    "            'bias': 1.0,\n",
    "            'word.lower()': word.lower(),\n",
    "            'postag': postag,\n",
    "            'word[-3:]': word[-3:],\n",
    "            'word[-2:]': word[-2:],\n",
    "            'word.isupper()': word.isupper(),\n",
    "            'word.istitle()': word.istitle(),\n",
    "            'word.isdigit()': word.isdigit(),\n",
    "            'word.first_letter': word[0],\n",
    "            'word.last_letter': word[-1],\n",
    "            'has_ingsuffix': word.endswith('ing'),\n",
    "            'prev_word': sent[i-1] if i > 0 else '<START>',\n",
    "            'next_word': sent[i+1] if i < len(sent)-1 else '<END>',\n",
    "            'prev_word_is_upper': sent[i-1].isupper() if i > 0 else False,\n",
    "            'next_word_is_upper': sent[i+1].isupper() if i < len(sent)-1 else False,\n",
    "            'pos_prefix': postag[:2],\n",
    "            'pos_suffix': postag[-2:],\n",
    "            'pos_category': postag[0],\n",
    "            'word.is_all_uppercase': word.isupper(),\n",
    "            'word.is_all_lowercase': word.islower(),\n",
    "            'word.is_mixed_case': not word.isupper() and not word.islower(),\n",
    "            'chunk':chunks[i],\n",
    "            'prev_chunk': chunks[i-1] if i > 0 else '<START>',\n",
    "            'next_chunk': chunks[i+1] if i < len(sent)-1 else '<END>',\n",
    "            # 'induced_pattern_1': check_for_induced_pattern_1(word, sent),\n",
    "            # 'induced_pattern_2': check_fors_induced_pattern_2(word, sent),\n",
    "            # add additional induced patterns as necessary\n",
    "        }\n",
    "    else:\n",
    "        features = {\n",
    "            'bias': 1.0,\n",
    "            'word.lower()': word.lower(),\n",
    "            'word[-3:]': word[-3:],\n",
    "            'word[-2:]': word[-2:],\n",
    "            'word.isupper()': word.isupper(),\n",
    "            'word.istitle()': word.istitle(),\n",
    "            'word.isdigit()': word.isdigit(),\n",
    "            'word.first_letter': word[0],\n",
    "            'word.last_letter': word[-1],\n",
    "            'has_ingsuffix': word.endswith('ing'),\n",
    "            'prev_word': sent[i-1] if i > 0 else '<START>',\n",
    "            'next_word': sent[i+1] if i < len(sent)-1 else '<END>',\n",
    "            'prev_word_is_upper': sent[i-1].isupper() if i > 0 else False,\n",
    "            'next_word_is_upper': sent[i+1].isupper() if i < len(sent)-1 else False,\n",
    "            'word.is_all_uppercase': word.isupper(),\n",
    "            'word.is_all_lowercase': word.islower(),\n",
    "            'word.is_mixed_case': not word.isupper() and not word.islower(),\n",
    "            # 'induced_pattern_1': check_for_induced_pattern_1(word, sent),\n",
    "            # 'induced_pattern_2': check_fors_induced_pattern_2(word, sent),\n",
    "            # add additional induced patterns as necessary\n",
    "        }\n",
    "    if entity_patterns != None:\n",
    "        token = token_list[i]\n",
    "        passed_patterns = []\n",
    "        for entity_in,patterns in entity_patterns.items():\n",
    "            if entity_in in ' '.join(sent):\n",
    "                if word in entity_in:\n",
    "                    if token != 'O':\n",
    "                        # print(' '.join(sent))\n",
    "                        #print(entity_in)\n",
    "                        # print(patterns)\n",
    "                        passed_patterns.append(patterns)\n",
    "\n",
    "        if len(passed_patterns)>0:\n",
    "            features['extracted entity'] = True\n",
    "            for i in range(len(passed_patterns)):\n",
    "                for j in range(len(passed_patterns[i])):\n",
    "                    features[f'pattern_{i*len(passed_patterns)+j}']=passed_patterns[i][j]\n",
    "        else:\n",
    "            features['extracted entity'] = False\n",
    "             \n",
    "        #print(word,passed_patterns)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'B-ORG', 'O', 'O']\n",
      "['He', 'went', 'to', 'the', 'Apple', 'store', '.']\n",
      "O He\n",
      "O went\n",
      "O to\n",
      "O the\n",
      "B-ORG Apple\n",
      "O store\n",
      "O .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/lorenzo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "#tokens = nltk.word_tokenize(\"Lorenzo goes to the University of Illinois at Urbana-Champaign\")\n",
    "tokens = nltk.word_tokenize(\"He went to the Apple store.\")\n",
    "\n",
    "features = [word2features(tokens, index,pos_tags_=None,entity_patterns = None,token_list=None,chunks=None) for index in range(len(tokens))]\n",
    "pred_labels = crf.predict([features])[0]\n",
    "print(pred_labels)\n",
    "print(tokens)\n",
    "for i in range(len(pred_labels)):\n",
    "    print(pred_labels[i], tokens[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Induction\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       B-LOC       0.88      0.87      0.88      1266\n",
    "      B-MISC       0.84      0.83      0.83       563\n",
    "       B-ORG       0.86      0.80      0.83      1229\n",
    "       B-PER       0.82      0.92      0.87      1025\n",
    "       I-LOC       0.85      0.72      0.78       220\n",
    "      I-MISC       0.73      0.67      0.70       162\n",
    "       I-ORG       0.82      0.75      0.78       515\n",
    "       I-PER       0.85      0.99      0.92       720\n",
    "           O       1.00      0.99      1.00      3411\n",
    "\n",
    "   micro avg       0.90      0.90      0.90      9111\n",
    "\n",
    "   macro avg       0.85      0.84      0.84      9111\n",
    "\n",
    "weighted avg       0.90      0.90      0.90      9111\n",
    "\n",
    " samples avg       0.92      0.91      0.91      9111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = joblib.load('crf_model_without_induction.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'B-LOC']\n",
      "['Lorenzo', 'goes', 'to', 'the', 'University', 'of', 'Illinois', 'at', 'Urbana-Champaign']\n",
      "O Lorenzo\n",
      "O goes\n",
      "O to\n",
      "O the\n",
      "B-ORG University\n",
      "I-ORG of\n",
      "I-ORG Illinois\n",
      "O at\n",
      "B-LOC Urbana-Champaign\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/lorenzo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "tokens = nltk.word_tokenize(\"Lorenzo goes to the University of Illinois at Urbana-Champaign\")\n",
    "\n",
    "features = [word2features(tokens, index,pos_tags_=None,entity_patterns = None,token_list=None,chunks=None) for index in range(len(tokens))]\n",
    "pred_labels = crf.predict([features])[0]\n",
    "print(pred_labels)\n",
    "print(tokens)\n",
    "for i in range(len(pred_labels)):\n",
    "    print(pred_labels[i], tokens[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without Induction\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       B-LOC       0.88      0.87      0.88      1266\n",
    "      B-MISC       0.82      0.83      0.82       563\n",
    "       B-ORG       0.86      0.80      0.83      1229\n",
    "       B-PER       0.83      0.92      0.87      1025\n",
    "       I-LOC       0.80      0.78      0.79       220\n",
    "      I-MISC       0.66      0.70      0.68       162\n",
    "       I-ORG       0.79      0.77      0.78       515\n",
    "       I-PER       0.86      0.98      0.92       720\n",
    "           O       1.00      0.99      1.00      3411\n",
    "\n",
    "   micro avg       0.90      0.91      0.90      9111\n",
    "\n",
    "   macro avg       0.83      0.85      0.84      9111\n",
    "   \n",
    "weighted avg       0.90      0.91      0.90      9111\n",
    "\n",
    " samples avg       0.91      0.91      0.90      9111"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://paperswithcode.com/sota/named-entity-recognition-ner-on-conll-2003?p=automated-concatenation-of-embeddings-for-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
